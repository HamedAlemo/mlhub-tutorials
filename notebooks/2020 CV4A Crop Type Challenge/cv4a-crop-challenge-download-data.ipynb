{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://radiant-assets.s3-us-west-2.amazonaws.com/PrimaryRadiantMLHubLogo.png' alt='Radiant MLHub Logo' width='300'/>\n",
    "\n",
    "# CV4A ICRL Crop Type Classification Challenge\n",
    "# A Guide to Access the data on Radiant MLHub\n",
    "\n",
    "\n",
    "This notebook walks you through the steps to get access to Radiant MLHub and access the data for the crop type classification competition being organized as part of the [CV4A](https://www.cv4gc.org/cv4a2020/) workshop at 2020 ICLR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radiant MLHub API\n",
    "\n",
    "\n",
    "The Radiant MLHub API gives access to open Earth imagery training data for machine learning applications. You can learn more about the repository at the [Radiant MLHub site](https://mlhub.earth) and about the organization behind it at the [Radiant Earth Foundation site](https://radiant.earth).\n",
    "\n",
    "Full documentation for the API is available at [docs.mlhub.earth](docs.mlhub.earth).\n",
    "\n",
    "Each item in our collection is explained in json format compliant with [STAC](https://stacspec.org/) [label extension](https://github.com/radiantearth/stac-spec/tree/master/extensions/label) definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output path where you want to download the data\n",
    "output_path = Path(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Access to the Radiant MLHub API requires an access token. To get your access token, go to [dashboard.mlhub.earth](https://dashboard.mlhub.earth). If you have not used Radiant MLHub before, you will need to sign up and create a new account. Otherwise, sign in. Under **Usage**, you'll see your access token, which you will need. *Do not share* your access token with others: your usage may be limited and sharing your access token is a security risk.\n",
    "\n",
    "Copy the access token, and paste it in the box bellow. This header block will work for all API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy your access token from dashboard.mlhub.earth and paste it in the following\n",
    "ACCESS_TOKEN = 'PASTE_YOUR_ACCESS_TOKEN_HERE'\n",
    "\n",
    "# these headers will be used in each request\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "    'Accept':'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the competition dataset\n",
    "\n",
    "Datasets are stored as collections on Radiant MLHub catalog. A collection represents the top-most data level. Typically this means the data comes from the same source for the same geography. It might include different years or sub-geographies.\n",
    "\n",
    "The two collections for this competition are:\n",
    "- `ref_african_crops_kenya_02_source`: includes the multi-temporal bands of Sentinel-2\n",
    "- `ref_african_crops_kenya_02_labels`: includes the labels and field IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_url(item, asset_key, headers):\n",
    "    asset = item.get('assets', {}).get(asset_key, None)\n",
    "    if asset is None:\n",
    "        print(f'Asset \"{asset_key}\" does not exist in this item')\n",
    "        return None\n",
    "    r = requests.get(asset.get('href'), headers=headers, allow_redirects=False)\n",
    "    return r.headers.get('Location')\n",
    "\n",
    "def download_label(url, output_path, tileid):\n",
    "    filename = urlparse(url).path.split('/')[-1]\n",
    "    outpath = output_path/tileid\n",
    "    outpath.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    f = open(outpath/filename, 'wb')\n",
    "    for chunk in r.iter_content(chunk_size=512 * 1024): \n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    print(f'Downloaded {filename}')\n",
    "    return \n",
    "\n",
    "def download_imagery(url, output_path, tileid, date):\n",
    "    filename = urlparse(url).path.split('/')[-1]\n",
    "    outpath = output_path/tileid/date\n",
    "    outpath.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    f = open(outpath/filename, 'wb')\n",
    "    for chunk in r.iter_content(chunk_size=512 * 1024): \n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    print(f'Downloaded {filename}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Labels\n",
    "\n",
    "\n",
    "The `assets` property of the items in a collection contains all the assets associated with that item and links to download them. The labels for the item will always be the asset with the key `labels`. The following code will go through every item in the collection and download the labels and field_ids raster feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# paste the id of the labels collection:\n",
    "collectionId = 'ref_african_crops_kenya_02_labels'\n",
    "\n",
    "# these optional parameters can be used to control what items are returned. \n",
    "# Here, we want to download all the items so:\n",
    "limit = 100 \n",
    "bounding_box = []\n",
    "date_time = []\n",
    "\n",
    "# retrieves the items and their metadata in the collection\n",
    "r = requests.get(f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items', params={'limit':limit, 'bbox':bounding_box,'datetime':date_time}, headers=headers)\n",
    "collection = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ref_african_crops_kenya_02_tile_02_label with the following assets ['field_train_test_ids', 'field_ids', 'labels']\n",
      "Feature ref_african_crops_kenya_02_tile_03_label with the following assets ['field_train_test_ids', 'field_ids', 'labels']\n",
      "Feature ref_african_crops_kenya_02_tile_01_label with the following assets ['field_train_test_ids', 'field_ids', 'labels']\n",
      "Feature ref_african_crops_kenya_02_tile_00_label with the following assets ['field_train_test_ids', 'field_ids', 'labels']\n"
     ]
    }
   ],
   "source": [
    "# retrieve list of features (in this case tiles) in the collection\n",
    "for feature in collection.get('features', []):\n",
    "    assets = feature.get('assets').keys()\n",
    "    print(\"Feature\", feature.get('id'), 'with the following assets', list(assets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 2_label.tif\n",
      "Downloaded 2_field_id.tif\n",
      "Downloaded 3_label.tif\n",
      "Downloaded 3_field_id.tif\n",
      "Downloaded 1_label.tif\n",
      "Downloaded 1_field_id.tif\n",
      "Downloaded 0_label.tif\n",
      "Downloaded 0_field_id.tif\n"
     ]
    }
   ],
   "source": [
    "for feature in collection.get('features', []):\n",
    "    \n",
    "    tileid = feature.get('id').split('tile_')[-1][:2]\n",
    "\n",
    "    # download labels\n",
    "    download_url = get_download_url(feature, 'labels', headers)\n",
    "    download_label(download_url, output_path, tileid)\n",
    "    \n",
    "    #download field_ids\n",
    "    download_url = get_download_url(feature, 'field_ids', headers)\n",
    "    download_label(download_url, output_path, tileid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Imagery\n",
    "\n",
    "The imagery items associated with the tiles are linked within the links array of the tile metadata. Links which have a rel type of \"source\" are links to imagery items. By requesting the metadata for the imagery item you can retrieve download URLs for each band of the imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell downloads all the multi-spectral images throughout the growing season for this competition.\n",
    "# The size of data is about 1.5 GB, and download time depends on your internet connection. \n",
    "# Note that you only need to run this cell and download the data once.\n",
    "for feature in collection.get('features', []):\n",
    "    for link in feature.get('links', []):\n",
    "        if link.get('rel') != 'source':\n",
    "            continue\n",
    "            \n",
    "        r = requests.get(link['href'], headers=headers)\n",
    "        feature = r.json()\n",
    "        assets = feature.get('assets').keys()\n",
    "        tileid = feature.get('id').split('tile_')[-1][:2]\n",
    "        date = datetime.strftime(datetime.strptime(feature.get('properties')['datetime'], \"%Y-%m-%dT%H:%M:%SZ\"), \"%Y%m%d\")\n",
    "        for asset in assets:\n",
    "            download_url = get_download_url(feature, asset, headers)\n",
    "            download_imagery(download_url, output_path, tileid, date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
