{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://radiant-assets.s3-us-west-2.amazonaws.com/PrimaryRadiantMLHubLogo.png' alt='Radiant MLHub Logo' width='300'/>\n",
    "\n",
    "How to use the Radiant MLHub API\n",
    "=====\n",
    "\n",
    "The Radiant MLHub API gives access to open Earth imagery training data for machine learning applications. You can learn more about the repository at the [Radiant MLHub site](https://mlhub.earth) and about the organization behind it at the [Radiant Earth Foundation site](https://radiant.earth).\n",
    "\n",
    "This Jupyter notebook, which you may copy and adapt for any use, shows basic examples of how to use the API. Full documentation for the API is available at [docs.mlhub.earth](docs.mlhub.earth).\n",
    "\n",
    "We'll show you how to set up your authorization, see the list of available collections and datasets, and retrieve the items (the data contained within them) from those collections. \n",
    "\n",
    "Each item in our collection is explained in json format compliant with [STAC](https://stacspec.org/) [label extension](https://github.com/radiantearth/stac-spec/tree/master/extensions/label) definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authentication\n",
    "-----\n",
    "\n",
    "Access to the Radiant MLHub API requires an access token. To get your access token, go to [dashboard.mlhub.earth](https://dashboard.mlhub.earth). If you have not used Radiant MLHub before, you will need to sign up and create a new account. Otherwise, sign in. Under **Usage**, you'll see your access token, which you will need. *Do not share* your access token with others: your usage may be limited and sharing your access token is a security risk.\n",
    "\n",
    "Copy the access token, and paste it in the box bellow. This header block will work for all API calls.\n",
    "\n",
    "Click **Run** or press `SHIFT` + `ENTER` before moving on to run this first piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the requests module is required to access the API\n",
    "import requests\n",
    "\n",
    "# copy your access token from dashboard.mlhub.earth and paste it in the following\n",
    "ACCESS_TOKEN = 'PASTE_YOUR_ACCESS_TOKEN_HERE'\n",
    "\n",
    "# these headers will be used in each request\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "    'Accept':'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for data collections\n",
    "-----\n",
    "\n",
    "To see what training data is available, you will want to see the collections available through the API.\n",
    "\n",
    "A collection represents the top-most data level. Typically this means the data comes from the same source for the same geography. It might include different years or sub-geographies.\n",
    "\n",
    "To find data with specific parameters, see the [API documentation](http://docs.mlhub.earth/?python#the-feature-collections-in-the-dataset).\n",
    "\n",
    "To see the list, simply run the following cell. The returned list shows the collection id values, collection license, and data source citation (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:       microsoft_chesapeake_nlcd\n",
      "License:  None\n",
      "Citation: Robinson C, Hou L, Malkin K, Soobitsky R, Czawlytko J, Dilkina B, Jojic N. Large Scale High-Resolution Land Cover Mapping with Multi-Resolution Data. Proceedings of the 2019 Conference on Computer Vision and Pattern Recognition (CVPR 2019).\n",
      "\n",
      "ID:       ref_african_crops_uganda_01\n",
      "License:  CC-BY-4.0\n",
      "Citation: Bocquet, C., Dalberg Data Insights. (2019) Dalberg Data Insights Uganda Crop Classification, Version 1. [Indicate subset used]. Radiant ML Hub. [Date Accessed]\n",
      "\n",
      "ID:       ref_african_crops_tanzania_01\n",
      "License:  CC-BY-4.0\n",
      "Citation: Great African Food Company. (2019) Great African Food Company Tanzania Ground Reference Crop Type Dataset, Version 1. [Indicate subset used]. Radiant ML Hub. [Date Accessed]\n",
      "\n",
      "ID:       ref_african_crops_kenya_02_source\n",
      "License:  CC-BY-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       ref_african_crops_kenya_02_labels\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       sn_AOI_3_Paris\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       sn_AOI_2_Vegas\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       sn_AOI_4_Shanghai\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       sn_AOI_5_Khartoum\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       ref_african_crops_kenya_01\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: PlantVillage. (2019) PlantVillage Kenya Ground Reference Crop Type Dataset, Version 1. [Indicate subset used]. Radiant ML Hub. [Date Accessed]\n",
      "\n",
      "ID:       microsoft_chesapeake_lc\n",
      "License:  None\n",
      "Citation: Robinson C, Hou L, Malkin K, Soobitsky R, Czawlytko J, Dilkina B, Jojic N. Large Scale High-Resolution Land Cover Mapping with Multi-Resolution Data. Proceedings of the 2019 Conference on Computer Vision and Pattern Recognition (CVPR 2019).\n",
      "\n",
      "ID:       microsoft_chesapeake_buildings\n",
      "License:  None\n",
      "Citation: Robinson C, Hou L, Malkin K, Soobitsky R, Czawlytko J, Dilkina B, Jojic N. Large Scale High-Resolution Land Cover Mapping with Multi-Resolution Data. Proceedings of the 2019 Conference on Computer Vision and Pattern Recognition (CVPR 2019).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get list of all collections\n",
    "r = requests.get('https://api.radiant.earth/mlhub/v1/collections', headers=headers)\n",
    "h = r.json()\n",
    "collections = h['collections']\n",
    "\n",
    "# print the list of collections \n",
    "for c in collections:\n",
    "    print(f'ID:       {c[\"id\"]}\\nLicense:  {c.get(\"license\", \"N/A\")}\\nCitation: {c.get(\"sci:citation\", \"N/A\")}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve properties of a collection\n",
    "----\n",
    "\n",
    "Once you have found the collection that you want to access, you can get its properties from the API.\n",
    "\n",
    "You can  limit what data you get in the response using the optional parameters:\n",
    "* **Limit** limits how many items will be returned, with a minimum of 1 and maximum of 10000.\n",
    "* **Bounding box** limits the returned items to a specific geographic area. \n",
    "* **Date time** limits the returned items to those that fall within a specific time-frame.\n",
    "\n",
    "See the [get features](http://docs.mlhub.earth/#getfeatures) API documentation for more information.\n",
    "\n",
    "Paste the collection id below for `collectionId`, and enter any desired parameters, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# paste the id of the collection you are interested in here:\n",
    "collectionId = 'ref_african_crops_kenya_01'\n",
    "# use these optional parameters to control what items are returned. maximum limit is 10000\n",
    "limit = 10\n",
    "bounding_box = []\n",
    "date_time = []\n",
    "\n",
    "# retrieves the items and their metadata in the collection\n",
    "r = requests.get(f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items', params={'limit':limit, 'bbox':bounding_box,'datetime':date_time},headers=headers)\n",
    "collection = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = None\n",
    "assets = None\n",
    "for feature in collection.get('features', []):\n",
    "    selected_item = feature\n",
    "    assets = list(feature.get('assets').keys())\n",
    "    # For demo purposes we only want the first item\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing Available Assets\n",
    "---\n",
    "\n",
    "Source imagery assets follow the pattern `year_month_day_type` so we'll loop through the list of assets and only print the ones which don't match that pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "documentation\n",
      "property_descriptions\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# List all assets which don't match the pattern \"year_month_day_*\"\n",
    "for asset in assets:\n",
    "    if not re.match('\\d{4}_\\d{2}_\\d{2}_.*', asset):\n",
    "        print(asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are 3 assets which match this criteria: `labels`, `documentation`, and `property descriptions`.\n",
    "\n",
    "Downloading Assets\n",
    "---\n",
    "We'll need to set up some functions to download assets first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_download_url(item, asset_key, headers):\n",
    "    asset = item.get('assets', {}).get(asset_key, None)\n",
    "    if asset is None:\n",
    "        print(f'Asset \"{asset_key}\" does not exist in this item')\n",
    "        return None\n",
    "    r = requests.get(asset.get('href'), headers=headers, allow_redirects=False)\n",
    "    return r.headers.get('Location')\n",
    "\n",
    "def download_file(url):\n",
    "    filename = urlparse(url).path.split('/')[-1]\n",
    "    r = requests.get(url)\n",
    "    f = open(filename, 'wb')\n",
    "    for chunk in r.iter_content(chunk_size=512 * 1024): \n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    print(f'Downloaded {filename}')\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Labels\n",
    "---\n",
    "\n",
    "We can download the `labels` asset by calling the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded ref_african_crops_kenya_01_001.geojson\n"
     ]
    }
   ],
   "source": [
    "download_file(get_download_url(selected_item, 'labels', headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Metadata\n",
    "---\n",
    "\n",
    "Likewise, we can download the documentation pdf and property description csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Documentation.pdf\n",
      "Downloaded properties.csv\n"
     ]
    }
   ],
   "source": [
    "download_file(get_download_url(selected_item, 'documentation', headers))\n",
    "download_file(get_download_url(selected_item, 'property_descriptions', headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Source Imagery\n",
    "---\n",
    "\n",
    "For this example, we'll query the API for the download url for a Sentinel 2 true color scene associated with this asset. Since the Sentinel2 S3 bucket is in Requester Pays mode, you must provide your AWS Access Key ID and Secret Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "AWS_ACCESS_KEY_ID = 'AKIAI3LS3WZBTCYC62QQ'\n",
    "AWS_SECRET_KEY = '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'\n",
    "\n",
    "def download_s3_file(url, access_key, secret_key):\n",
    "    parsed_url = urlparse(url)\n",
    "    \n",
    "    bucket = parsed_url.hostname.split('.')[0]\n",
    "    path = parsed_url.path[1:]\n",
    "    filename = path.split('/')[-1]\n",
    "    \n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_KEY\n",
    "    )\n",
    "    \n",
    "    s3.download_file(bucket, path, filename, ExtraArgs={'RequestPayer': 'requester'})\n",
    "    print(f'Downloaded s3://{bucket}/{path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded s3://sentinel-s2-l1c/tiles/36/N/XF/2019/7/31/0/TCI.jp2\n"
     ]
    }
   ],
   "source": [
    "true_color_asset_url = get_download_url(selected_item, '2019_07_31_tci', headers)\n",
    "download_s3_file(true_color_asset_url, AWS_ACCESS_KEY_ID, AWS_SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
