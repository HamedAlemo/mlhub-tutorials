{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://radiant-assets.s3-us-west-2.amazonaws.com/PrimaryRadiantMLHubLogo.png' alt='Radiant MLHub Logo' width='300'/>\n",
    "\n",
    "How to use the Radiant MLHub API to browse and download the BigEarthNet dataset\n",
    "=====\n",
    "\n",
    "This Jupyter notebook, which you may copy and adapt for any use, shows basic examples of how to use the API to download labels and source imagery for the BigEarthNet dataset. Full documentation for the API is available at [docs.mlhub.earth](docs.mlhub.earth).\n",
    "\n",
    "We'll show you how to set up your authorization, see the list of available collections and datasets, and retrieve the items (the data contained within them) from those collections. \n",
    "\n",
    "Each item in our collection is explained in json format compliant with [STAC](https://stacspec.org/) [label extension](https://github.com/radiantearth/stac-spec/tree/master/extensions/label) definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authentication\n",
    "-----\n",
    "\n",
    "Access to the Radiant MLHub API requires an access token. To get your access token, go to [dashboard.mlhub.earth](https://dashboard.mlhub.earth). If you have not used Radiant MLHub before, you will need to sign up and create a new account. Otherwise, sign in. Under **Usage**, you'll see your access token, which you will need. *Do not share* your access token with others: your usage may be limited and sharing your access token is a security risk.\n",
    "\n",
    "Copy the access token, and paste it in the box bellow. This header block will work for all API calls.\n",
    "\n",
    "Click **Run** or press `SHIFT` + `ENTER` before moving on to run this first piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the requests module is required to access the API\n",
    "import requests\n",
    "\n",
    "# copy your access token from dashboard.mlhub.earth and paste it in the following\n",
    "ACCESS_TOKEN = 'PASTE_YOUR_ACCESS_TOKEN_HERE'\n",
    "\n",
    "# these headers will be used in each request\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
    "    'Accept':'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for data collections\n",
    "-----\n",
    "\n",
    "To see what training data is available, you will want to see the collections available through the API.\n",
    "\n",
    "A collection represents the top-most data level. Typically this means the data comes from the same source for the same geography. It might include different years or sub-geographies.\n",
    "\n",
    "To find data with specific parameters, see the [API documentation](http://docs.mlhub.earth/?python#the-feature-collections-in-the-dataset).\n",
    "\n",
    "To see the list, simply run the following cell. The returned list shows the collection id values, collection license, and data source citation (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:       ref_african_crops_uganda_01\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: Bocquet, C., Dalberg Data Insights. (2019) Dalberg Data Insights Uganda Crop Classification, Version 1. [Indicate subset used]. Radiant ML Hub. [Date Accessed]\n",
      "\n",
      "ID:       microsoft_chesapeake_nlcd\n",
      "License:  CDLA-permissive-1.0\n",
      "Citation: Robinson C, Hou L, Malkin K, Soobitsky R, Czawlytko J, Dilkina B, Jojic N. Large Scale High-Resolution Land Cover Mapping with Multi-Resolution Data. Proceedings of the 2019 Conference on Computer Vision and Pattern Recognition (CVPR 2019).\n",
      "\n",
      "ID:       ref_african_crops_tanzania_01\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: Great African Food Company. (2019) Great African Food Company Tanzania Ground Reference Crop Type Dataset, Version 1. [Indicate subset used]. Radiant ML Hub. [Date Accessed]\n",
      "\n",
      "ID:       ref_african_crops_kenya_02_source\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: Radiant Earth Foundation (2020) CV4A Competition Kenya Crop Type Dataset, Version 1. [Indicate subset used]. Radiant ML Hub. [Date Accessed]\n",
      "\n",
      "ID:       microsoft_chesapeake_landsat_leaf_on\n",
      "License:  See https://landsat.usgs.gov/sites/default/files/documents/Landsat_Data_Policy.pdf\n",
      "Citation: Robinson C, Hou L, Malkin K, Soobitsky R, Czawlytko J, Dilkina B, Jojic N. Large Scale High-Resolution Land Cover Mapping with Multi-Resolution Data. Proceedings of the 2019 Conference on Computer Vision and Pattern Recognition (CVPR 2019).\n",
      "\n",
      "ID:       bigearthnet_v1_labels\n",
      "License:  CDLA-Permissive-1.0\n",
      "Citation: G. Sumbul, M. Charfuelan, B. Demir, V. Markl, \"BigEarthNet: A Large-Scale Benchmark Archive for Remote Sensing Image Understanding\", IEEE International Geoscience and Remote Sensing Symposium, pp. 5901-5904, Yokohama, Japan, 2019.\n",
      "\n",
      "ID:       bigearthnet_v1_source\n",
      "License:  CDLA-Permissive-1.0\n",
      "Citation: G. Sumbul, M. Charfuelan, B. Demir, V. Markl, \"BigEarthNet: A Large-Scale Benchmark Archive for Remote Sensing Image Understanding\", IEEE International Geoscience and Remote Sensing Symposium, pp. 5901-5904, Yokohama, Japan, 2019.\n",
      "\n",
      "ID:       ref_african_crops_imagery_01\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       ref_african_crops_kenya_02_labels\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: Radiant Earth Foundation (2020) CV4A Competition Kenya Crop Type Dataset, Version 1. [Indicate subset used]. Radiant ML Hub. [Date Accessed]\n",
      "\n",
      "ID:       microsoft_chesapeake_naip\n",
      "License:  public domain with attribution\n",
      "Citation: Robinson C, Hou L, Malkin K, Soobitsky R, Czawlytko J, Dilkina B, Jojic N. Large Scale High-Resolution Land Cover Mapping with Multi-Resolution Data. Proceedings of the 2019 Conference on Computer Vision and Pattern Recognition (CVPR 2019).\n",
      "\n",
      "ID:       microsoft_chesapeake_landsat_leaf_off\n",
      "License:  See https://landsat.usgs.gov/sites/default/files/documents/Landsat_Data_Policy.pdf\n",
      "Citation: Robinson C, Hou L, Malkin K, Soobitsky R, Czawlytko J, Dilkina B, Jojic N. Large Scale High-Resolution Land Cover Mapping with Multi-Resolution Data. Proceedings of the 2019 Conference on Computer Vision and Pattern Recognition (CVPR 2019).\n",
      "\n",
      "ID:       ref_african_crops_kenya_01\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: PlantVillage. (2019) PlantVillage Kenya Ground Reference Crop Type Dataset, Version 1. [Indicate subset used]. Radiant ML Hub. [Date Accessed]\n",
      "\n",
      "ID:       microsoft_chesapeake_lc\n",
      "License:  CDLA-permissive-1.0\n",
      "Citation: Robinson C, Hou L, Malkin K, Soobitsky R, Czawlytko J, Dilkina B, Jojic N. Large Scale High-Resolution Land Cover Mapping with Multi-Resolution Data. Proceedings of the 2019 Conference on Computer Vision and Pattern Recognition (CVPR 2019).\n",
      "\n",
      "ID:       microsoft_chesapeake_buildings\n",
      "License:  CDLA-permissive-1.0\n",
      "Citation: Robinson C, Hou L, Malkin K, Soobitsky R, Czawlytko J, Dilkina B, Jojic N. Large Scale High-Resolution Land Cover Mapping with Multi-Resolution Data. Proceedings of the 2019 Conference on Computer Vision and Pattern Recognition (CVPR 2019).\n",
      "\n",
      "ID:       sn_AOI_3_Paris\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       sn_AOI_2_Vegas\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       sn_AOI_4_Shanghai\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n",
      "ID:       sn_AOI_5_Khartoum\n",
      "License:  CC-BY-SA-4.0\n",
      "Citation: N/A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get list of all collections\n",
    "r = requests.get('https://api.radiant.earth/mlhub/v1/collections', headers=headers)\n",
    "h = r.json()\n",
    "collections = h['collections']\n",
    "\n",
    "# print the list of collections \n",
    "for c in collections:\n",
    "    print(f'ID:       {c[\"id\"]}\\nLicense:  {c.get(\"license\", \"N/A\")}\\nCitation: {c.get(\"sci:citation\", \"N/A\")}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the query properties\n",
    "----\n",
    "\n",
    "The BigEarthNet dataset is split into two collections, one which contains the labels and one which contains the source imagery. Labels link to their respective source imagery items so we will set our collection ID to `bigearthnet_v1_labels`.\n",
    "\n",
    "You can  limit what data you get in the response using the optional parameters:\n",
    "* **Limit** limits how many items will be returned, with a minimum of 1 and maximum of 10000.\n",
    "\n",
    "We will limit the amount of results returned per page to 100 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collectionId = 'bigearthnet_v1_labels'\n",
    "limit = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Items\n",
    "----\n",
    "\n",
    "The next cell contains the functions which page through the results and download the labels and source imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 # Required to download assets hosted on S3\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def download_s3(uri, path):\n",
    "    parsed = urlparse(uri)\n",
    "    bucket = parsed.netloc\n",
    "    key = parsed.path[1:]\n",
    "    s3.download_file(bucket, key, os.path.join(path, key.split('/')[-1]))\n",
    "    print(f'Downloaded s3://{bucket}/{key}')\n",
    "    \n",
    "def download_http(uri, path):\n",
    "    parsed = urlparse(uri)\n",
    "    r = requests.get(uri)\n",
    "    f = open(os.path.join(path, parsed.path[1:]), 'wb')\n",
    "    for chunk in r.iter_content(chunk_size=512 * 1024): \n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    print(f'Downloaded {uri}')\n",
    "\n",
    "def get_download_uri(uri):\n",
    "    r = requests.get(uri, allow_redirects=False)\n",
    "    return r.headers['Location']\n",
    "\n",
    "def download(href, path):\n",
    "    download_uri = get_download_uri(href)\n",
    "    parsed = urlparse(download_uri)\n",
    "    \n",
    "    if parsed.scheme in ['s3']:\n",
    "        download_s3(download_uri, path)\n",
    "    elif parsed.scheme in ['http', 'https']:\n",
    "        download_http(download_uri, path)\n",
    "\n",
    "def download_source_and_labels(item):\n",
    "    labels = item.get('assets').get('labels')\n",
    "    links = item.get('links')\n",
    "    \n",
    "    # Make the directory to download the files to\n",
    "    path = f'bigearthnet/{item[\"id\"]}/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    # Download the labels\n",
    "    download(labels['href'], path)\n",
    "    \n",
    "    #Download the source imagery\n",
    "    for link in links:\n",
    "        if link['rel'] != 'source':\n",
    "            continue\n",
    "        \n",
    "        r = requests.get(link['href'], headers=headers)\n",
    "        for key, asset in r.json()['assets'].items():\n",
    "            download(asset['href'], path)\n",
    "            \n",
    "def get_items(uri, classes=None, cloud_and_shadow=None, seasonal_snow=None, max_items_downloaded=None, items_downloaded=0):\n",
    "    r = requests.get(uri, headers=headers)\n",
    "    collection = r.json()\n",
    "    for feature in collection.get('features', []):\n",
    "        # Check if the item has one of the label classes we're interested in\n",
    "        matches_class = True\n",
    "        if classes is not None:\n",
    "            matches_class = False\n",
    "            for label_class in feature['properties'].get('labels', []):\n",
    "                if label_class in classes:\n",
    "                    matches_class = True\n",
    "                    break\n",
    "        \n",
    "        # Check if the item matches the cloud and shadows filter we specify\n",
    "        matches_clouds = True\n",
    "        if cloud_and_shadow is not None:\n",
    "            matches_clouds = feature['properties'].get('cloud_and_shadow', False) == cloud_and_shadow\n",
    "            \n",
    "        \n",
    "        # Check if the item matches the seasonal snow filter we specify\n",
    "        matches_snow = True\n",
    "        if seasonal_snow is not None:\n",
    "            matches_snow = feature['properties'].get('seasonal_snow', False) == seasonal_snow\n",
    "            \n",
    "        # If the item does not match all of the criteria we specify, skip it\n",
    "        if not matches_class or not matches_clouds or not matches_snow:\n",
    "            continue\n",
    "            \n",
    "        # Download the label and source imagery for the item\n",
    "        download_source_and_labels(feature)\n",
    "        \n",
    "        # Stop downloaded items if we reached the maximum we specify\n",
    "        items_downloaded += 1\n",
    "        if max_items_downloaded is not None and items_downloaded >= max_items_downloaded:\n",
    "            return\n",
    "        \n",
    "    # Get the next page if results, if available\n",
    "    for link in collection['links']:\n",
    "        if link['rel'] == 'next' and link['href'] is not None:\n",
    "            get_items(link['href'], classes=classes, cloud_and_shadow=cloud_and_shadow, seasonal_snow=seasonal_snow, max_items_downloaded=max_items_downloaded, items_downloaded=items_downloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing total number of tiles\n",
    "----\n",
    "\n",
    "To find the total number of tiles in the dataset we will query the collection for an item and read the \"numberMatched\" property which contains the total number of tiles in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tiles: 590326\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items?limit=1', headers=headers)\n",
    "print(f'Total Number of Tiles: {r.json()[\"numberMatched\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading all labels\n",
    "----\n",
    "\n",
    "This next cell will download all labels and source imagery contained in the BigEarthnet dataset. For demonstration purposes in this notebook, we limit the number of items downloaded to 1. You can remove the `max_items_downloaded` argument and the function will download all 590,326 labels and source imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded s3://radiant-mlhub/bigearthnet/labels/S2A_MSIL2A_20180529T115401_33_74.geojson\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B01.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B02.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B03.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B04.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B05.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B06.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B07.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B08.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B09.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B11.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B12.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_33_74/S2A_MSIL2A_20180529T115401_33_74_B8A.tif\n"
     ]
    }
   ],
   "source": [
    "get_items(f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items?limit={limit}', max_items_downloaded=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering downloads based of labels\n",
    "----\n",
    "\n",
    "A likely scenario is you only want to download tiles which contain certain land cover classes or tiles which are not cloudy. First you'll need to know which land cover classes are contained in the dataset so you know which ones to filter on. The next cell will query the API and return the possible values for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes for labels\n",
      "- Agro-forestry areas\n",
      "- Airports\n",
      "- Annual crops associated with permanent crops\n",
      "- Bare rock\n",
      "- Beaches, dunes, sands\n",
      "- Broad-leaved forest\n",
      "- Burnt areas\n",
      "- Coastal lagoons\n",
      "- Complex cultivation patterns\n",
      "- Coniferous forest\n",
      "- Construction sites\n",
      "- Continuous urban fabric\n",
      "- Discontinuous urban fabric\n",
      "- Dump sites\n",
      "- Estuaries\n",
      "- Fruit trees and berry plantations\n",
      "- Green urban areas\n",
      "- Industrial or commercial units\n",
      "- Inland marshes\n",
      "- Intertidal flats\n",
      "- Land principally occupied by agriculture, with significant areas of natural vegetation\n",
      "- Mineral extraction sites\n",
      "- Mixed forest\n",
      "- Moors and heathland\n",
      "- Natural grassland\n",
      "- Non-irrigated arable land\n",
      "- Olive groves\n",
      "- Pastures\n",
      "- Peatbogs\n",
      "- Permanently irrigated land\n",
      "- Port areas\n",
      "- Rice fields\n",
      "- Road and rail networks and associated land\n",
      "- Salines\n",
      "- Salt marshes\n",
      "- Sclerophyllous vegetation\n",
      "- Sea and ocean\n",
      "- Sparsely vegetated areas\n",
      "- Sport and leisure facilities\n",
      "- Transitional woodland/shrub\n",
      "- Vineyards\n",
      "- Water bodies\n",
      "- Water courses\n",
      "\n",
      "Classes for seasonal_snow\n",
      "- False\n",
      "- True\n",
      "\n",
      "Classes for cloud_and_shadow\n",
      "- False\n",
      "- True\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items?limit=1', headers=headers)\n",
    "label_classes = r.json()['features'][0]['properties']['label:classes']\n",
    "for label_class in label_classes:\n",
    "    print(f'\\nClasses for {label_class[\"name\"]}')\n",
    "    for c in sorted(label_class['classes']):\n",
    "        print(f'- {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering downloads on label classes, cloud and shadows, and seasonal snow\n",
    "----\n",
    "\n",
    "The labels in BigEarthNet have three properties.\n",
    "1) An array of land cover type classes contained in the tile\n",
    "2) Whether the tile contains cloud and cloud shadows\n",
    "3) Whether the tile has seasonal snow\n",
    "\n",
    "We can filter our download based off one or more of the properties.\n",
    "\n",
    "In this next cell we will download the first 5 tiles which contain either the `Coniferous forest` or `Rice fields` classes, do not contain clouds and cloud shadows, and do not contain seasonal snow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded s3://radiant-mlhub/bigearthnet/labels/S2A_MSIL2A_20180529T115401_65_71.geojson\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B01.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B02.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B03.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B04.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B05.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B06.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B07.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B08.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B09.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B11.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B12.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_65_71/S2A_MSIL2A_20180529T115401_65_71_B8A.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/labels/S2A_MSIL2A_20180529T115401_67_77.geojson\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B01.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B02.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B03.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B04.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B05.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B06.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B07.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B08.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B09.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B11.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B12.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_67_77/S2A_MSIL2A_20180529T115401_67_77_B8A.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/labels/S2A_MSIL2A_20180529T115401_56_89.geojson\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B01.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B02.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B03.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B04.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B05.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B06.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B07.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B08.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B09.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B11.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B12.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_56_89/S2A_MSIL2A_20180529T115401_56_89_B8A.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/labels/S2A_MSIL2A_20180529T115401_57_78.geojson\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B01.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B02.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B03.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B04.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B05.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B06.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B07.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B08.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B09.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B11.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B12.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_57_78/S2A_MSIL2A_20180529T115401_57_78_B8A.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/labels/S2A_MSIL2A_20180529T115401_53_69.geojson\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_53_69/S2A_MSIL2A_20180529T115401_53_69_B01.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_53_69/S2A_MSIL2A_20180529T115401_53_69_B02.tif\n",
      "Downloaded s3://radiant-mlhub/bigearthnet/S2A_MSIL2A_20180529T115401_53_69/S2A_MSIL2A_20180529T115401_53_69_B03.tif\n"
     ]
    }
   ],
   "source": [
    "get_items(\n",
    "    f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items?limit={limit}',\n",
    "    classes=['Coniferous forest', 'Rice fields'],\n",
    "    cloud_and_shadow=False,\n",
    "    seasonal_snow=False,\n",
    "    max_items_downloaded=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
